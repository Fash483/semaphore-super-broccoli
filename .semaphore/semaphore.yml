version: 2.1

jobs:
  build:
    docker:
      - image: cimg/node:18.17
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: npm install
      - run:
          name: Build project
          command: npm run build

  download_and_upload:
    docker:
      - image: cimg/node:18.17
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            npm install webtorrent-cli
            sudo apt-get update
            sudo apt-get install -y python3 python3-pip
            pip3 install requests
      - run:
          name: Download torrent
          command: |
            npx webtorrent download "magnet:?xt=urn:btih:73630FD012B6DC42C3F4B07BD7FD19138C8C9C3F&dn=Pie+to+Die+For+A+Hannah+Swensen+Mystery+2025+1080p+WEB-DL+HEVC+x265+BONE" --out ./downloads --quiet
      - run:
          name: Create and run recursive upload script
          command: |
            cat <<'EOF' > upload_files_recursive.py
            import os
            import requests
            import concurrent.futures

            directory = 'downloads'
            url_template = 'https://filebin.net/Sahaujwsh/{filename}'

            def upload_file(file_path):
                filename = os.path.relpath(file_path, directory).replace(os.sep, '/')
                print(f'Starting upload: {filename}')
                with open(file_path, 'rb') as f:
                    response = requests.post(
                        url_template.format(filename=filename),
                        headers={
                            'accept': 'application/json',
                            'Content-Type': 'application/octet-stream'
                        },
                        data=f
                    )
                try:
                    response_data = response.json()
                except Exception:
                    response_data = response.text
                print(f'Finished upload: {filename} with status {response.status_code}')
                return filename, response.status_code, response_data

            # Walk through directory recursively
            files = []
            for root, dirs, filenames in os.walk(directory):
                for f in filenames:
                    files.append(os.path.join(root, f))

            # Upload files concurrently
            with concurrent.futures.ThreadPoolExecutor() as executor:
                futures = [executor.submit(upload_file, file) for file in files]
                for future in concurrent.futures.as_completed(futures):
                    filename, status_code, response_data = future.result()
                    print(f'Uploaded {filename}: Status {status_code}, Response: {response_data}')
            EOF
      - run:
          name: Run the recursive upload script
          command: |
            python3 upload_files_recursive.py

workflows:
  version: 2
  upload_workflow:
    jobs:
      - build
      - download_and_upload
